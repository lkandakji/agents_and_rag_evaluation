{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734ab45a-eac6-46bb-bed7-2eaac6ab701a",
   "metadata": {},
   "source": [
    "# Evaluating Agent Trajectories via Tool-Use Consistency\n",
    "\n",
    "This notebook implements an evaluation framework for agentic systems that explicitly assesses **intermediate decision-making**, rather than relying solely on final answers. The focus is on diagnosing cases where agents appear correct at the output level while following unintended reasoning paths internally.\n",
    "\n",
    "## Motivation: Evaluating process, not just outcome\n",
    "\n",
    "Agentic systems built on large language models make decisions through sequences of tool calls and intermediate reasoning steps. In practice, I observed that evaluating these systems purely on final answer correctness often masks important failure modes: agents may arrive at correct answers through spurious searches, unnecessary tool usage, or coincidental reasoning paths that do not generalize.\n",
    "\n",
    "This notebook focuses on **trajectory-level evaluation**: assessing whether an agent’s *sequence of actions* matches an expected decision process. The goal is not to enforce a single “correct” reasoning path, but to detect cases where agents rely on shortcuts or exhibit unstable behaviour that would not be apparent from output-level metrics alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-4a7b-8c9d-1e2f3a4b5c6d",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "\n",
    "The experiments below use a small, controlled evaluation dataset in which each example includes:\n",
    "- a user query,\n",
    "- a reference final answer,\n",
    "- and an expected sequence of tool calls representing a minimal, intended decision path.\n",
    "\n",
    "This structure allows us to compare the agent’s observed trajectory against a known baseline and isolate deviations in tool use independently of answer correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fdc4da-d656-47eb-9298-198a5a7a3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The '%pip install' command installs python packages from the notebook.\n",
    "# -U flag ensures we get the latest versions of langchain and openai.\n",
    "%pip install -U langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-f6a7-b8c9-d0e1-f2a3b4c5d6e7",
   "metadata": {},
   "source": [
    "Next, we configure our environment variables. This is a secure way to provide API keys to our application.\n",
    "\n",
    "- **`LANGCHAIN_API_KEY`**: Your secret key for authenticating with LangSmith.\n",
    "- **`OPENAI_API_KEY`**: Your secret key for the OpenAI API, required for the agent's LLM.\n",
    "- **`LANGCHAIN_ENDPOINT`**: This URL directs all LangChain tracing data to the LangSmith platform.\n",
    "\n",
    "**Action Required**: You must replace the placeholder values with your actual keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1303f-a7bb-4098-bf13-598d9893d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Import the 'os' module to interact with the operating system.\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR API KEY\" # Set your LangSmith API key as an environment variable.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI API KEY\" # Set your OpenAI API key as an environment variable.\n",
    "# Update with your API URL if using a hosted instance of Langsmith.\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\" # Set the LangSmith API endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526e117",
   "metadata": {},
   "source": [
    "## Dataset Construction\n",
    "\n",
    "Each evaluation example contains an `expected_steps` field specifying the ordered list of tools the agent is expected to invoke. This serves as a lightweight form of ground truth for the agent’s decision process.\n",
    "\n",
    "For queries that do not require external tools, the expected trajectory is intentionally empty. This enables us to detect unnecessary tool usage, which is a common failure mode in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129154f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid # Import the uuid library to generate unique identifiers.\n",
    "\n",
    "from langsmith import Client # Import the Client class to interact with LangSmith.\n",
    "\n",
    "client = Client() # Instantiate the LangSmith client.\n",
    "\n",
    "# Define the list of questions and their corresponding outputs.\n",
    "questions = [\n",
    "    (\n",
    "        \"Why was was a $10 calculator app one of the best-rated Nintendo Switch games?\",\n",
    "        {\n",
    "            \"reference\": \"It became an internet meme due to its high price point.\", # The ground-truth final answer.\n",
    "            \"expected_steps\": [\"duck_duck_go\"], # The expected sequence of tool calls.\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"hi\",\n",
    "        {\n",
    "            \"reference\": \"Hello, how can I assist you?\", # The expected direct response.\n",
    "            \"expected_steps\": [],  # Expect a direct response with no tools used.\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Who is Dejan Trajkov?\",\n",
    "        {\n",
    "            \"reference\": \"Macedonian Professor, Immunologist and Physician\",\n",
    "            \"expected_steps\": [\"duck_duck_go\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Who won the 2023 U23 world wresting champs (men's freestyle 92 kg)\",\n",
    "        {\n",
    "            \"reference\": \"Muhammed Gimri from turkey\",\n",
    "            \"expected_steps\": [\"duck_duck_go\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"What's my first meeting on Friday?\",\n",
    "        {\n",
    "            \"reference\": 'Your first meeting is 8:30 AM for \"Team Standup\"',\n",
    "            \"expected_steps\": [\"check_calendar\"],  # Only expect the calendar tool to be used.\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "uid = uuid.uuid4() # Generate a new unique identifier.\n",
    "dataset_name = f\"Agent Eval Example {uid}\" # Create a unique name for the dataset.\n",
    "# Create the dataset on the LangSmith platform.\n",
    "ds = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"An example agent evals dataset using search and calendar checks.\",\n",
    ")\n",
    "# Create the examples in the dataset.\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q[0]} for q in questions], # The inputs are a list of question dictionaries.\n",
    "    outputs=[q[1] for q in questions], # The outputs are a list of the corresponding output dictionaries.\n",
    "    dataset_id=ds.id, # Link these examples to the dataset we just created.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc0a4c-e9a9-490c-91af-c702e35fad08",
   "metadata": {},
   "source": [
    "## Agent Definition\n",
    "\n",
    "The agent used here is intentionally simple and constrained. It has access to:\n",
    "- a web search tool,\n",
    "- and a mock calendar lookup function.\n",
    "\n",
    "The purpose is not to optimise task performance, but to create a controlled environment where deviations in tool usage are easy to interpret. The agent executor is configured to return intermediate steps so that trajectories can be analysed post hoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa875e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse # A utility to parse date strings into datetime objects.\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent # Import core agent components.\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions # A formatting helper.\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser # The output parser.\n",
    "from langchain_openai import ChatOpenAI # The OpenAI chat model wrapper.\n",
    "from langchain_community.tools import DuckDuckGoSearchResults # The DuckDuckGo search tool.\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder # Prompting utilities.\n",
    "from langchain_core.tools import tool # The decorator for creating custom tools.\n",
    "from langchain_core.utils.function_calling import format_tool_to_openai_function # A function formatting helper.\n",
    "\n",
    "\n",
    "# The '@tool' decorator easily turns a Python function into a LangChain tool.\n",
    "@tool\n",
    "def check_calendar(date: str) -> list:\n",
    "    \"\"\"Check the user's calendar for a meetings on the specified datetime (in iso format).\"\"\" # The docstring is used as the tool's description for the agent.\n",
    "    date_time = parse(date) # Parse the input date string.\n",
    "    # This is a mock implementation to demonstrate the concept.\n",
    "    if date_time.weekday() == 4: # 4 corresponds to Friday.\n",
    "        return [\n",
    "            \"8:30 : Team Standup\",\n",
    "            \"9:00 : 1 on 1\",\n",
    "            \"9:45 design review\",\n",
    "        ]\n",
    "    return [\"Focus time\"] # Return a default for other days.\n",
    "\n",
    "\n",
    "# Define the main function that creates and runs our agent.\n",
    "def agent(inputs: dict):\n",
    "    # Initialize the LLM. We use a model that's good at function calling.\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        temperature=0, # Set temperature to 0 for more deterministic, repeatable outputs.\n",
    "    )\n",
    "    # Define the list of tools the agent has access to.\n",
    "    tools = [\n",
    "        DuckDuckGoSearchResults(\n",
    "            name=\"duck_duck_go\" # Give the tool a specific name.\n",
    "        ),\n",
    "        check_calendar, # Our custom calendar tool.\n",
    "    ]\n",
    "    # Define the prompt template for the agent.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a helpful assistant.\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # Placeholder for intermediate steps.\n",
    "            (\"user\", \"{question}\"), # Placeholder for the user's input question.\n",
    "        ]\n",
    "    )\n",
    "    # Create the runnable agent component.\n",
    "    runnable_agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "    # Create the Agent Executor, which orchestrates the agent's runs.\n",
    "    executor = AgentExecutor(\n",
    "        agent=runnable_agent,\n",
    "        tools=tools,\n",
    "        handle_parsing_errors=True, # Gracefully handle any parsing errors.\n",
    "        return_intermediate_steps=True, # CRITICAL: This must be True to get the trajectory for evaluation.\n",
    "    )\n",
    "    # Invoke the executor with the inputs.\n",
    "    return executor.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464d318",
   "metadata": {},
   "source": [
    "## Trajectory Consistency Evaluator\n",
    "\n",
    "We define a custom evaluator that compares the agent’s observed tool-use trajectory to the expected sequence specified in the dataset.\n",
    "\n",
    "This evaluator is deliberately strict: it scores a run as correct only when the tool sequence matches exactly. While this does not capture all valid reasoning paths, it provides a clear signal for identifying shortcut behaviour, unnecessary tool calls, or deviations caused by prompt sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c701d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional # Import typing hints.\n",
    "\n",
    "from langsmith.schemas import Example, Run # Import the Run and Example schemas from LangSmith.\n",
    "\n",
    "\n",
    "# Define the custom evaluator function.\n",
    "def intermediate_step_correctness(run: Run, example: Optional[Example] = None) -> dict:\n",
    "    if run.outputs is None: # A safety check to ensure the run has completed and has outputs.\n",
    "        raise ValueError(\"Run outputs cannot be None\")\n",
    "    # Get the 'intermediate_steps' from the agent's output, defaulting to an empty list if not found.\n",
    "    intermediate_steps = run.outputs.get(\"intermediate_steps\") or []\n",
    "    # The intermediate_steps list contains tuples of (AgentAction, observation).\n",
    "    # We only care about the action's 'tool' attribute.\n",
    "    # This list comprehension extracts the tool name for each step.\n",
    "    trajectory = [action.tool for action, _ in intermediate_steps]\n",
    "    # Retrieve the ground-truth trajectory from our dataset example.\n",
    "    expected_trajectory = example.outputs[\"expected_steps\"]\n",
    "    # Perform a simple equality check between the actual and expected trajectories.\n",
    "    score = int(trajectory == expected_trajectory)\n",
    "    # Return the result in the format required by LangSmith.\n",
    "    return {\"key\": \"Intermediate steps correctness\", \"score\": score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8568f90",
   "metadata": {},
   "source": [
    "## Running the Evaluation\n",
    "\n",
    "We run two complementary evaluators:\n",
    "1. A standard QA evaluator that checks final answer correctness.\n",
    "2. A custom trajectory evaluator that checks consistency of tool usage.\n",
    "\n",
    "Separating these signals allows us to distinguish between:\n",
    "- failures of knowledge or retrieval, and\n",
    "- failures of decision-making or control flow.\n",
    "\n",
    "In practice, I found that these two metrics often diverge, highlighting cases where agents appear correct while behaving unreliably internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5201d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: _get_url() https://links.duckduckgo.com/d.js DuckDuckGoSearchException: Ratelimit\\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate # Import the evaluation functions.\n",
    "\n",
    "\n",
    "# Define a data preparation function for the standard QA evaluator.\n",
    "def prepare_data(run: Run, example: Example) -> dict:\n",
    "    # This function creates the specific dictionary that the 'qa' evaluator expects.\n",
    "    return {\n",
    "        \"input\": example.inputs[\"question\"], # The original question.\n",
    "        \"prediction\": run.outputs[\"output\"], # The agent's final answer.\n",
    "        \"reference\": example.outputs[\"reference\"], # The ground-truth final answer.\n",
    "    }\n",
    "\n",
    "\n",
    "# Create an instance of the standard QA evaluator, passing our data preparation function.\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", prepare_data=prepare_data)\n",
    "\n",
    "# Run the full evaluation.\n",
    "chain_results = evaluate(\n",
    "    agent, # The agent function to be tested.\n",
    "    data=dataset_name, # The name of our dataset in LangSmith.\n",
    "    # A list containing both our custom evaluator and the standard QA evaluator.\n",
    "    evaluators=[intermediate_step_correctness, qa_evaluator],\n",
    "    experiment_prefix=\"Agent Eval Example\", # A prefix for the experiment name in LangSmith.\n",
    "    max_concurrency=1, # Run sequentially as some agents/tools may not be thread-safe.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe01d96-bfde-4979-a1e3-c6c70759d9b7",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "This evaluation setup demonstrates how trajectory-level analysis can surface failure modes that are invisible to output-based metrics alone. Even in simple settings, agents frequently arrive at correct answers through unintended or unstable sequences of actions.\n",
    "\n",
    "While the evaluator implemented here is intentionally simple, it provides a useful baseline for diagnosing agent behaviour and motivates more flexible approaches (e.g. partial matches, semantic trajectory grading) in settings where multiple decision paths may be acceptable.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
